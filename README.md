# å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ

åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)çš„LLMå¹»è§‰æ£€æµ‹ä¸çº æ­£ä¸€ä½“åŒ–æ¡†æ¶ï¼Œé€šè¿‡æ„å›¾åˆ†ç±»ã€è¯æ®æ£€ç´¢ã€ç»“æ„åŒ–éªŒè¯å’Œæ„å›¾æ„ŸçŸ¥çº æ­£ï¼Œå®ç°å¯¹å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹çš„è‡ªåŠ¨æ£€æµ‹ä¸ä¿®æ­£ã€‚

## æ ¸å¿ƒç‰¹æ€§

- ğŸ¯ **æ„å›¾æ„ŸçŸ¥**: è‡ªåŠ¨è¯†åˆ«æŸ¥è¯¢æ„å›¾ï¼Œé’ˆå¯¹æ€§å¤„ç†
- ğŸ” **è¯æ®é©±åŠ¨**: åŸºäºæƒå¨çŸ¥è¯†åº“è¿›è¡Œäº‹å®æ ¸æŸ¥
- âœ… **ç»“æ„åŒ–éªŒè¯**: æ ‡å‡†åŒ–çš„å£°æ˜éªŒè¯æµç¨‹
- âœï¸ **æ™ºèƒ½çº æ­£**: æ„å›¾ç‰¹å®šçš„ç­”æ¡ˆé‡å†™ç­–ç•¥
- ğŸ“Š **å¯è§£é‡Šæ€§**: å®Œæ•´çš„éªŒè¯è½¨è¿¹å’Œçº æ­£ä¾æ®
- ğŸš€ **é«˜æ€§èƒ½**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†

## é¡¹ç›®ç»“æ„
```
llm-hallucination-correction/
â”œâ”€â”€ src/                          # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ core/                     # æ ¸å¿ƒæµç¨‹æ§åˆ¶
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ orchestrator.py       # æµç¨‹åè°ƒå™¨ï¼ˆä¸»æ§åˆ¶å™¨ï¼‰
â”‚   â”œâ”€â”€ llm/                      # LLMç›¸å…³æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_client.py         # LLMå®¢æˆ·ç«¯é€‚é…å™¨ï¼ˆå¤šæä¾›å•†æ”¯æŒï¼‰
â”‚   â”‚   â””â”€â”€ prompt_templates.py   # Promptæ¨¡æ¿ç®¡ç†ç³»ç»Ÿ
â”‚   â”œâ”€â”€ retrieval/                # æ£€ç´¢æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ vector_retriever.py   # å‘é‡æ£€ç´¢å™¨ï¼ˆåŸºäºChromaDBï¼‰
â”‚   â”œâ”€â”€ verification/             # éªŒè¯æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ intent_classifier.py  # æ„å›¾åˆ†ç±»å™¨
â”‚   â”‚   â”œâ”€â”€ claim_extractor.py    # å£°æ˜æå–å™¨
â”‚   â”‚   â””â”€â”€ evidence_verifier.py  # è¯æ®éªŒè¯å™¨
â”‚   â””â”€â”€ correction/              # çº æ­£æ¨¡å—
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ answer_corrector.py   # ç­”æ¡ˆçº æ­£å™¨
â”œâ”€â”€ config/                       # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.yaml              # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/                         # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ knowledge_base/          # çŸ¥è¯†åº“æ–‡æ¡£ï¼ˆåŸå§‹æ–‡æœ¬ï¼‰
â”‚   â””â”€â”€ vector_db/               # å‘é‡æ•°æ®åº“å­˜å‚¨
â”œâ”€â”€ tests/                       # æµ‹è¯•ä»£ç ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_llm_client.py       # LLMå®¢æˆ·ç«¯æµ‹è¯•
â”‚   â”œâ”€â”€ test_retrieval.py        # æ£€ç´¢æ¨¡å—æµ‹è¯•
â”‚   â””â”€â”€ test_full_pipeline.py   # å®Œæ•´æµç¨‹æµ‹è¯•
â”œâ”€â”€ docs/                        # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ api.md                  # APIæ¥å£æ–‡æ¡£
â”‚   â””â”€â”€ deployment.md           # éƒ¨ç½²æŒ‡å—
â”œâ”€â”€ scripts/                     # è„šæœ¬ç›®å½•
â”‚   â”œâ”€â”€ setup_knowledge_base.py # çŸ¥è¯†åº“åˆå§‹åŒ–è„šæœ¬
â”‚   â””â”€â”€ batch_processing.py     # æ‰¹é‡å¤„ç†è„šæœ¬
â”œâ”€â”€ main.py                      # ä¸»å…¥å£æ–‡ä»¶
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–åˆ—è¡¨
â”œâ”€â”€ .env.example                 # ç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶
â”œâ”€â”€ .gitignore                  # Gitå¿½ç•¥è§„åˆ™
â””â”€â”€ README.md                   # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

ç¯å¢ƒè¦æ±‚

 - Python: 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
 - å†…å­˜: è‡³å°‘ 8GB RAM
 - å­˜å‚¨: è‡³å°‘ 10GB å¯ç”¨ç©ºé—´
 - ç½‘ç»œ: ç¨³å®šçš„äº’è”ç½‘è¿æ¥ï¼ˆç”¨äºAPIè°ƒç”¨ï¼‰

## å®‰è£…æ­¥éª¤

å…‹éš†é¡¹ç›®ä»“åº“ 
```
git clone https://github.com/your-org/llm-hallucination-correction.git
cd llm-hallucination-correction
```
åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
```
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate     # Windows
å®‰è£…ä¾èµ–åŒ…
pip install -r requirements.txt
é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„APIå¯†é’¥å’Œå…¶ä»–é…ç½®
åˆå§‹åŒ–çŸ¥è¯†åº“
python scripts/setup_knowledge_base.py
åŸºæœ¬ä½¿ç”¨
å‘½ä»¤è¡Œäº¤äº’æ¨¡å¼
python main.py --interactive
å¤„ç†å•ä¸ªæŸ¥è¯¢
python main.py --query "æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ"
æ‰¹é‡å¤„ç†æ–‡ä»¶ä¸­çš„æŸ¥è¯¢
python main.py --file queries.txt --export json
æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
python main.py --status
```

## âš™ï¸ é…ç½®è¯´æ˜

ä¸»è¦é…ç½®é¡¹:

é…ç½®æ–‡ä»¶ä½äº config/config.yamlï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

LLMæä¾›å•†é…ç½®
```
llm:
  provider: "deepseek"           # æˆ– "openai", "anthropic"
  api_key: "${DEEPSEEK_API_KEY}" # ä»ç¯å¢ƒå˜é‡è¯»å–
  model: "deepseek-chat"
  base_url: "https://api.deepseek.com/v1"
  temperature: 0.1
  max_tokens: 1000
```

å‘é‡æ•°æ®åº“é…ç½®
```
vector_db:
  embedding_model: "BAAI/bge-base-en"
  db_path: "./data/vector_db"
  collection_name: "knowledge_base"
```

æ£€ç´¢é…ç½®
```
retrieval:
  similarity_threshold: 0.7
  max_retrieved_docs: 5
```

éªŒè¯é…ç½®
```
verification:
  confidence_threshold: 0.8
  max_verification_attempts: 3
```

ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º .envæ–‡ä»¶å¹¶é…ç½®ä»¥ä¸‹å˜é‡ï¼š

APIå¯†é’¥é…ç½®
```
DEEPSEEK_API_KEY=your_deepseek_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
```

ç³»ç»Ÿé…ç½®
```
LOG_LEVEL=INFO
MAX_CONCURRENT_REQUESTS=5
REQUEST_TIMEOUT=30
```

çŸ¥è¯†åº“é…ç½®
```
KNOWLEDGE_BASE_PATH=./data/knowledge_base
VECTOR_DB_PATH=./data/vector_db
```

## ğŸ§© æ ¸å¿ƒæ¨¡å—è¯¦è§£

 - LLMå®¢æˆ·ç«¯é€‚é…å™¨ (src/llm/llm_client.py),æ”¯æŒå¤šæä¾›å•†ï¼ˆDeepSeekã€OpenAIã€Anthropicç­‰ï¼‰

ç»Ÿä¸€çš„APIè°ƒç”¨æ¥å£

å†…ç½®é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†

ä½¿ç”¨ç¤ºä¾‹ï¼š

```
from src.llm.llm_client import LLMAdapter
llm = LLMAdapter("deepseek", config)
response = llm.call("ä½ çš„æç¤ºè¯", max_tokens=500)
```

 - Promptæ¨¡æ¿ç®¡ç†ç³»ç»Ÿ (src/llm/prompt_templates.py)
   
é›†ä¸­ç®¡ç†æ‰€æœ‰æç¤ºè¯æ¨¡æ¿

æ”¯æŒæ„å›¾åˆ†ç±»ã€å£°æ˜æå–ã€äº‹å®éªŒè¯ã€ç­”æ¡ˆçº æ­£ç­‰åœºæ™¯

æ„å›¾ç‰¹å®šçš„æ¨¡æ¿å®šåˆ¶

ä½¿ç”¨ç¤ºä¾‹ï¼š
```
from src.llm.prompt_templates import PromptTemplates

templates = PromptTemplates()
prompt = templates.get_intent_classification_prompt("ä½ çš„æŸ¥è¯¢")
```

 - å‘é‡æ£€ç´¢å™¨ (src/retrieval/vector_retriever.py)
   
åŸºäºChromaDBçš„å‘é‡ç›¸ä¼¼æ€§æ£€ç´¢

æ”¯æŒå¤šç§åµŒå…¥æ¨¡å‹ï¼ˆSentence Transformersï¼‰

å¯é…ç½®çš„ç›¸ä¼¼åº¦é˜ˆå€¼å’Œç»“æœæ•°é‡

ä½¿ç”¨ç¤ºä¾‹ï¼š
```
from src.retrieval.vector_retriever import VectorRetriever

retriever = VectorRetriever(config)
results = retriever.search("æŸ¥è¯¢æ–‡æœ¬", n_results=5)
```
 - æµç¨‹åè°ƒå™¨ (src/core/orchestrator.py)

æ•´åˆæ‰€æœ‰æ¨¡å—çš„å®Œæ•´å·¥ä½œæµ

çŠ¶æ€ç®¡ç†å’Œé”™è¯¯å¤„ç†

æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•

ä½¿ç”¨ç¤ºä¾‹ï¼š
```
from src.core.orchestrator import EvidenceEnhancedCorrectionOrchestrator

orchestrator = EvidenceEnhancedCorrectionOrchestrator(config)
result = orchestrator.process_query("ä½ çš„æŸ¥è¯¢")
```

# ğŸ“Š APIæ¥å£
å•æ¬¡æŸ¥è¯¢å¤„ç†
```
POST /api/process
Content-Type: application/json

{
  "query": "æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ",
  "context": "å¯é€‰ä¸Šä¸‹æ–‡ä¿¡æ¯"
}
å“åº”ç¤ºä¾‹ï¼š
{
  "success": true,
  "query": "æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ",
  "results": {
    "initial_answer": "åˆå§‹å›ç­”å†…å®¹...",
    "corrected_answer": "çº æ­£åå›ç­”å†…å®¹...",
    "intent": "äº‹å®æŸ¥è¯¢",
    "verifications": [...],
    "hallucination_analysis": {...}
  },
  "processing_metadata": {...}
}
æ‰¹é‡å¤„ç†æ¥å£
POST /api/batch-process
Content-Type: application/json

{
  "queries": ["æŸ¥è¯¢1", "æŸ¥è¯¢2", "æŸ¥è¯¢3"],
  "context": "å…±äº«ä¸Šä¸‹æ–‡ä¿¡æ¯"
}
```
# ğŸ§ª æµ‹è¯•ä¸éªŒè¯
è¿è¡Œå•å…ƒæµ‹è¯• 
```
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•æ¨¡å—
python -m pytest tests/test_llm_client.py -v

# å¸¦è¦†ç›–ç‡æŠ¥å‘Š
python -m pytest --cov=src tests/
æµ‹è¯•æ•°æ®å‡†å¤‡
åˆ›å»ºæµ‹è¯•æŸ¥è¯¢æ–‡ä»¶ test_queries.txtï¼š
ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ
Pythonå’ŒJavaçš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ
å¦‚ä½•å­¦ä¹ æ·±åº¦å­¦ä¹ ï¼Ÿ
äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•å‰æ™¯
æ€§èƒ½åŸºå‡†æµ‹è¯•
ç³»ç»ŸåŒ…å«æ€§èƒ½æµ‹è¯•è„šæœ¬ï¼Œå¯è¯„ä¼°å¤„ç†é€Ÿåº¦å’Œèµ„æºä½¿ç”¨ï¼š
python tests/performance_benchmark.py --queries 100 --workers 4
```
# ğŸš¢ éƒ¨ç½²æŒ‡å—
æœ¬åœ°éƒ¨ç½²

å®‰è£…ä¾èµ–ï¼š```pip install -r requirements.txt```

é…ç½®ç¯å¢ƒå˜é‡

åˆå§‹åŒ–çŸ¥è¯†åº“

å¯åŠ¨æœåŠ¡ï¼š```python main.py --interactiveæˆ–ä½¿ç”¨WSGIæœåŠ¡å™¨```

Dockeréƒ¨ç½²
```
FROM python:3.9-slim

WORKDIR /app
COPY . .
RUN pip install -r requirements.txt

EXPOSE 8000
CMD ["python", "main.py", "--host", "0.0.0.0", "--port", "8000"]
```

æ„å»ºå’Œè¿è¡Œï¼š
```
docker build -t llm-hallucination-correction .
docker run -p 8000:8000 llm-hallucination-correction
```
äº‘éƒ¨ç½²å»ºè®®

AWS: ä½¿ç”¨EC2æˆ–Lambda + S3å­˜å‚¨çŸ¥è¯†åº“

Azure: Azure Functions + Blob Storage

GCP: Cloud Functions + Cloud Storage

å»ºè®®é…ç½®ï¼šè‡³å°‘4æ ¸CPUï¼Œ8GBå†…å­˜ï¼Œ50GBå­˜å‚¨

# ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

ç³»ç»Ÿåœ¨æ ‡å‡†ç¡¬ä»¶é…ç½®ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼š

å•æ¬¡æŸ¥è¯¢å¤„ç†æ—¶é—´: 2-5ç§’ï¼ˆå–å†³äºæŸ¥è¯¢å¤æ‚åº¦å’Œè¯æ®æ£€ç´¢æ—¶é—´ï¼‰

å¹¶å‘å¤„ç†èƒ½åŠ›: æ”¯æŒ5-10ä¸ªå¹¶å‘æŸ¥è¯¢

å‡†ç¡®ç‡: 85-95%ï¼ˆåŸºäºéªŒè¯ç»“æœç½®ä¿¡åº¦ï¼‰

å¹»è§‰æ£€æµ‹ç‡: å¯è¯†åˆ«80%ä»¥ä¸Šçš„å¸¸è§å¹»è§‰ç±»å‹

# ğŸ¤ è´¡çŒ®æŒ‡å—
æˆ‘ä»¬æ¬¢è¿ç¤¾åŒºè´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

Forkæœ¬é¡¹ç›®

åˆ›å»ºç‰¹æ€§åˆ†æ”¯ï¼š```git checkout -b feature/AmazingFeature```

æäº¤æ›´æ”¹ï¼š```git commit -m 'Add AmazingFeature'```

æ¨é€åˆ°åˆ†æ”¯ï¼š```git push origin feature/AmazingFeature```

æäº¤Pull Request

å¼€å‘è§„èŒƒ

éµå¾ªPEP 8ä»£ç é£æ ¼

ç¼–å†™é€‚å½“çš„å•å…ƒæµ‹è¯•

æ›´æ–°ç›¸å…³æ–‡æ¡£

ä½¿ç”¨ç±»å‹æç¤ºï¼ˆType Hintsï¼‰

æ·»åŠ æ–°åŠŸèƒ½

åœ¨ç›¸åº”æ¨¡å—ä¸­å®ç°æ–°åŠŸèƒ½

æ·»åŠ æµ‹è¯•ç”¨ä¾‹

æ›´æ–°é…ç½®æ¨¡æ¿ï¼ˆå¦‚éœ€è¦ï¼‰

æ–‡æ¡£åŒ–æ–°åŠŸèƒ½çš„ä½¿ç”¨æ–¹æ³•

# ğŸ“ å¸¸è§é—®é¢˜è§£ç­”
Q: å¦‚ä½•æ·»åŠ æ–°çš„LLMæä¾›å•†ï¼Ÿ

A: åœ¨ src/llm/llm_client.pyä¸­çš„ LLMAdapterç±»æ·»åŠ æ–°æä¾›å•†çš„æ”¯æŒï¼Œå®ç°ç›¸åº”çš„APIè°ƒç”¨é€»è¾‘ã€‚


Q: å¦‚ä½•æ‰©å±•çŸ¥è¯†åº“ï¼Ÿ

A: å°†æ–‡æ¡£æ”¾å…¥ data/knowledge_base/ç›®å½•ï¼Œç„¶åè¿è¡Œ python scripts/setup_knowledge_base.pyé‡æ–°åˆå§‹åŒ–å‘é‡æ•°æ®åº“ã€‚


Q: å¦‚ä½•å¤„ç†å¤§é‡å¹¶å‘è¯·æ±‚ï¼Ÿ

A: è°ƒæ•´é…ç½®ä¸­çš„ max_concurrent_requestså‚æ•°ï¼Œå¹¶è€ƒè™‘ä½¿ç”¨å¼‚æ­¥å¤„ç†æˆ–éƒ¨ç½²å¤šä¸ªå®ä¾‹ã€‚


Q: å¦‚ä½•è‡ªå®šä¹‰éªŒè¯è§„åˆ™ï¼Ÿ

A: ä¿®æ”¹ src/verification/evidence_verifier.pyä¸­çš„éªŒè¯é€»è¾‘ï¼Œæˆ–è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼é…ç½®ã€‚


# ğŸ“œ è®¸å¯è¯ 

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ LICENSEæ–‡ä»¶ã€‚

# ğŸ† è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„è´¡çŒ®ï¼š

ChromaDBï¼šå‘é‡æ•°æ®åº“è§£å†³æ–¹æ¡ˆ

Sentence Transformersï¼šæ–‡æœ¬åµŒå…¥æ¨¡å‹

FastAPIï¼šé«˜æ€§èƒ½APIæ¡†æ¶

Pytestï¼šæµ‹è¯•æ¡†æ¶

# ğŸ”„ ç‰ˆæœ¬å†å²

v1.0.0â€‹ (2024-03-20)

åˆå§‹ç‰ˆæœ¬å‘å¸ƒ

æ”¯æŒDeepSeekå’ŒOpenAIæä¾›å•†

å®Œæ•´çš„å¹»è§‰æ£€æµ‹ä¸çº æ­£æµç¨‹

åŸºç¡€APIæ¥å£

æ³¨æ„: æœ¬é¡¹ç›®ä»åœ¨ç§¯æå¼€å‘ä¸­ï¼ŒAPIå’Œé…ç½®æ ¼å¼å¯èƒ½å‘ç”Ÿå˜åŒ–ã€‚å»ºè®®å®šæœŸæŸ¥çœ‹æ›´æ–°æ—¥å¿—å’Œæ–‡æ¡£ã€‚

ä¸‹æ¬¡å†™(d â€¢_â€¢)d
