#!/usr/bin/env python3
"""
æµç¨‹åè°ƒå™¨ - ä¸»æµç¨‹æ§åˆ¶å™¨
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œå®ç°å®Œæ•´çš„å¹»è§‰æ£€æµ‹ä¸çº æ­£æµç¨‹
"""

import time
import json
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
from src.llm.llm_client import LLMAdapter
from src.llm.prompt_templates import PromptTemplates
from src.retrieval.vector_retriever import VectorRetriever
from src.verification.intent_classifier import IntentClassifier
from src.verification.claim_extractor import ClaimExtractor
from src.verification.evidence_verifier import EvidenceVerifier
from src.correction.answer_corrector import AnswerCorrector

class EvidenceEnhancedCorrectionOrchestrator:
    """è¯æ®å¢å¼ºçš„çº é”™åè°ƒå™¨ - ä¸»æµç¨‹æ§åˆ¶å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = self._setup_logging()
        self.components = self._initialize_components()
        self.logger.info("âœ… ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logging.basicConfig(
            level=getattr(logging, self.config.get('system', {}).get('log_level', 'INFO')),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)
    
    def _initialize_components(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        llm_config = self.config['llm']
        
        # åˆå§‹åŒ–LLMé€‚é…å™¨
        llm_adapter = LLMAdapter(llm_config['provider'], llm_config)
        
        # åˆå§‹åŒ–å„æ¨¡å—
        components = {
            'llm_adapter': llm_adapter,
            'templates': PromptTemplates(),
            'vector_retriever': VectorRetriever(self.config['vector_db']),
            'intent_classifier': IntentClassifier(llm_adapter, self.config['intent']),
            'claim_extractor': ClaimExtractor(llm_adapter),
            'evidence_verifier': EvidenceVerifier(llm_adapter, self.config['verification']),
            'answer_corrector': AnswerCorrector(llm_adapter)
        }
        
        return components
    
    def process_query(self, query: str, context: Optional[str] = None) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢çš„å®Œæ•´æµç¨‹"""
        start_time = time.time()
        execution_steps = {}
        results = {}
        
        try:
            self.logger.info(f"ğŸ” å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")
            
            # æ­¥éª¤1: ç”Ÿæˆåˆå§‹å›ç­”
            initial_answer, step_meta = self._generate_initial_answer(query, context)
            execution_steps['initial_answer_generation'] = step_meta
            results['initial_answer'] = initial_answer
            self.logger.info(f"ğŸ“ ç”Ÿæˆåˆå§‹ç­”æ¡ˆ (é•¿åº¦: {len(initial_answer)} å­—ç¬¦)")
            
            # æ­¥éª¤2: æ„å›¾åˆ†ç±»
            intent, step_meta = self._classify_intent(query)
            execution_steps['intent_classification'] = step_meta
            results['intent'] = intent
            self.logger.info(f"ğŸ¯ æ£€æµ‹åˆ°æ„å›¾: {intent}")
            
            # æ­¥éª¤3: å£°æ˜æå–
            claims, step_meta = self._extract_claims(initial_answer)
            execution_steps['claim_extraction'] = step_meta
            results['claims'] = claims
            self.logger.info(f"ğŸ” æå–åˆ° {len(claims)} ä¸ªå£°æ˜")
            
            # æ­¥éª¤4: è¯æ®æ£€ç´¢
            evidence_map, step_meta = self._retrieve_evidence(query, claims, intent)
            execution_steps['evidence_retrieval'] = step_meta
            results['evidence_map'] = evidence_map
            self.logger.info("ğŸ“š è¯æ®æ£€ç´¢å®Œæˆ")
            
            # æ­¥éª¤5: å£°æ˜éªŒè¯
            verifications, step_meta = self._verify_claims(claims, evidence_map, query, intent)
            execution_steps['claim_verification'] = step_meta
            results['verifications'] = verifications
            self.logger.info(f"âœ… å®Œæˆå£°æ˜éªŒè¯: {len(verifications)} ä¸ªå£°æ˜")
            
            # æ­¥éª¤6: ç­”æ¡ˆçº æ­£
            corrected_answer, step_meta = self._correct_answer(
                initial_answer, verifications, query, intent
            )
            execution_steps['answer_correction'] = step_meta
            results['corrected_answer'] = corrected_answer
            self.logger.info(f"âœï¸ ç­”æ¡ˆçº æ­£å®Œæˆ")
            
            # æ­¥éª¤7: å¹»è§‰æ£€æµ‹
            hallucination_analysis, step_meta = self._detect_hallucinations(
                query, initial_answer, corrected_answer, evidence_map
            )
            execution_steps['hallucination_detection'] = step_meta
            results['hallucination_analysis'] = hallucination_analysis
            self.logger.info("ğŸ”¬ å¹»è§‰æ£€æµ‹å®Œæˆ")
            
            # æ­¥éª¤8: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            final_report = self._generate_final_report(results, execution_steps)
            results['final_report'] = final_report
            
            total_duration = time.time() - start_time
            self.logger.info(f"ğŸ‰ æµç¨‹å®Œæˆ! æ€»è€—æ—¶: {total_duration:.2f}ç§’")
            
            return {
                'success': True,
                'query': query,
                'results': results,
                'execution_steps': execution_steps,
                'processing_metadata': {
                    'total_duration': total_duration,
                    'timestamp': datetime.now().isoformat(),
                    'steps_completed': list(execution_steps.keys())
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
            return {
                'success': False,
                'query': query,
                'error': str(e),
                'processing_metadata': {
                    'timestamp': datetime.now().isoformat(),
                    'error_step': self._identify_error_step(execution_steps)
                }
            }
    
    def _generate_initial_answer(self, query: str, context: Optional[str]) -> tuple[str, Dict]:
        """ç”Ÿæˆåˆå§‹å›ç­”"""
        start_time = time.time()
        
        prompt = self.components['templates'].get_initial_answer_prompt(query)
        if context:
            prompt = f"ä¸Šä¸‹æ–‡: {context}\n\n{prompt}"
        
        response = self.components['llm_adapter'].call_with_retry(prompt)
        
        duration = time.time() - start_time
        return response['text'], {
            'duration': duration,
            'prompt_length': len(prompt),
            'response_length': len(response['text']),
            'llm_usage': response.get('usage', {})
        }
    
    def _classify_intent(self, query: str) -> tuple[str, Dict]:
        """åˆ†ç±»æŸ¥è¯¢æ„å›¾"""
        start_time = time.time()
        
        intent = self.components['intent_classifier'].classify_intent(query)
        
        duration = time.time() - start_time
        return intent, {
            'duration': duration,
            'detected_intent': intent
        }
    
    def _extract_claims(self, text: str) -> tuple[List[Dict], Dict]:
        """ä»æ–‡æœ¬ä¸­æå–å£°æ˜"""
        start_time = time.time()
        
        claims = self.components['claim_extractor'].extract_claims(text)
        validation = self.components['claim_extractor'].validate_claims(claims)
        
        duration = time.time() - start_time
        return claims, {
            'duration': duration,
            'claims_count': len(claims),
            'validation_metrics': validation
        }
    
    def _retrieve_evidence(self, query: str, claims: List[Dict], intent: str) -> tuple[Dict, Dict]:
        """æ£€ç´¢ç›¸å…³è¯æ®"""
        start_time = time.time()
        
        evidence_map = {}
        total_evidence_count = 0
        
        for claim in claims:
            claim_id = claim['id']
            claim_text = claim['text']
            
            # ä¸ºæ¯ä¸ªå£°æ˜æ£€ç´¢è¯æ®
            evidence_snippets = self.components['vector_retriever'].search(
                f"{query} {claim_text}", 
                n_results=3
            )
            
            evidence_map[claim_id] = {
                'claim': claim_text,
                'evidence': evidence_snippets,
                'retrieval_query': f"{query} {claim_text}"
            }
            total_evidence_count += len(evidence_snippets)
        
        duration = time.time() - start_time
        return evidence_map, {
            'duration': duration,
            'total_evidence_count': total_evidence_count,
            'claims_with_evidence': len(evidence_map)
        }
    
    def _verify_claims(self, claims: List[Dict], evidence_map: Dict, query: str, intent: str) -> tuple[List[Dict], Dict]:
        """éªŒè¯å£°æ˜çœŸå®æ€§"""
        start_time = time.time()
        
        verifications = []
        supported_count = 0
        contradicted_count = 0
        
        for claim in claims:
            claim_id = claim['id']
            
            if claim_id in evidence_map:
                evidence_info = evidence_map[claim_id]
                verification_result = self.components['evidence_verifier'].verify_claim(
                    claim['text'], evidence_info['evidence'], query, intent
                )
                
                if verification_result.get('verdict') == 'SUPPORTED':
                    supported_count += 1
                elif verification_result.get('verdict') == 'CONTRADICTED':
                    contradicted_count += 1
                
                verifications.append(verification_result)
            else:
                # æ²¡æœ‰æ£€ç´¢åˆ°è¯æ®çš„å£°æ˜
                verifications.append({
                    'claim_id': claim_id,
                    'claim': claim['text'],
                    'verdict': 'UNVERIFIED',
                    'confidence': 0.0,
                    'reasoning': 'æœªèƒ½æ£€ç´¢åˆ°ç›¸å…³è¯æ®è¿›è¡ŒéªŒè¯'
                })
        
        duration = time.time() - start_time
        return verifications, {
            'duration': duration,
            'total_verifications': len(verifications),
            'supported_count': supported_count,
            'contradicted_count': contradicted_count,
            'support_ratio': supported_count / len(verifications) if verifications else 0
        }
    
    def _correct_answer(self, initial_answer: str, verifications: List[Dict], query: str, intent: str) -> tuple[str, Dict]:
        """çº æ­£ç­”æ¡ˆ"""
        start_time = time.time()
        
        correction_result = self.components['answer_corrector'].correct_answer(
            initial_answer, verifications, query, intent
        )
        
        duration = time.time() - start_time
        return correction_result['corrected_answer'], {
            'duration': duration,
            'correction_metrics': {
                'supported_claims': correction_result.get('supported_claims', 0),
                'contradicted_claims': correction_result.get('contradicted_claims', 0),
                'length_change': len(correction_result['corrected_answer']) - len(initial_answer)
            }
        }
    
    def _detect_hallucinations(self, query: str, initial_answer: str, corrected_answer: str, evidence_map: Dict) -> tuple[Dict, Dict]:
        """æ£€æµ‹å¹»è§‰"""
        start_time = time.time()
        
        # å‡†å¤‡è¯æ®æ–‡æœ¬
        evidence_text = self._prepare_evidence_text(evidence_map)
        
        # ä½¿ç”¨å¹»è§‰æ£€æµ‹æ¨¡æ¿
        prompt = self.components['templates'].get_hallucination_detection_prompt(
            query, initial_answer, corrected_answer, evidence_text
        )
        
        response = self.components['llm_adapter'].call_with_retry(prompt)
        
        try:
            hallucination_analysis = json.loads(response['text'])
        except json.JSONDecodeError:
            hallucination_analysis = {
                'has_hallucination': False,
                'error': 'æ— æ³•è§£æå¹»è§‰æ£€æµ‹ç»“æœ',
                'raw_response': response['text'][:200]
            }
        
        duration = time.time() - start_time
        return hallucination_analysis, {
            'duration': duration,
            'detection_result': hallucination_analysis.get('has_hallucination', False)
        }
    
    def _prepare_evidence_text(self, evidence_map: Dict) -> str:
        """å‡†å¤‡è¯æ®æ–‡æœ¬"""
        evidence_parts = []
        for claim_id, info in evidence_map.items():
            evidence_parts.append(f"å£°æ˜: {info['claim']}")
            for i, evidence in enumerate(info['evidence'], 1):
                evidence_parts.append(f"è¯æ®{i}: {evidence['text']} (ç›¸ä¼¼åº¦: {evidence.get('similarity', 0):.3f})")
            evidence_parts.append("")
        
        return "\n".join(evidence_parts)
    
    def _generate_final_report(self, results: Dict, execution_steps: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        return {
            'summary': {
                'query': results.get('query'),
                'intent': results.get('intent'),
                'initial_answer_length': len(results.get('initial_answer', '')),
                'corrected_answer_length': len(results.get('corrected_answer', '')),
                'total_claims': len(results.get('claims', [])),
                'supported_claims': len([v for v in results.get('verifications', []) if v.get('verdict') == 'SUPPORTED']),
                'has_hallucination': results.get('hallucination_analysis', {}).get('has_hallucination', False)
            },
            'quality_metrics': {
                'answer_improvement': self._calculate_improvement_metric(results),
                'evidence_coverage': self._calculate_evidence_coverage(results),
                'verification_confidence': self._calculate_average_confidence(results)
            },
            'recommendations': self._generate_recommendations(results)
        }
    
    def _calculate_improvement_metric(self, results: Dict) -> float:
        """è®¡ç®—ç­”æ¡ˆæ”¹è¿›æŒ‡æ ‡"""
        initial_len = len(results.get('initial_answer', ''))
        corrected_len = len(results.get('corrected_answer', ''))
        
        if initial_len == 0:
            return 0.0
        
        # ç®€å•çš„æ”¹è¿›æŒ‡æ ‡ï¼šåŸºäºé•¿åº¦å˜åŒ–å’ŒéªŒè¯ç»“æœ
        length_ratio = corrected_len / initial_len
        supported_ratio = len([v for v in results.get('verifications', []) if v.get('verdict') == 'SUPPORTED']) / len(results.get('verifications', [1]))
        
        return (length_ratio + supported_ratio) / 2
    
    def _calculate_evidence_coverage(self, results: Dict) -> float:
        """è®¡ç®—è¯æ®è¦†ç›–ç‡"""
        claims = results.get('claims', [])
        evidence_map = results.get('evidence_map', {})
        
        if not claims:
            return 0.0
        
        covered_claims = sum(1 for claim in claims if claim['id'] in evidence_map)
        return covered_claims / len(claims)
    
    def _calculate_average_confidence(self, results: Dict) -> float:
        """è®¡ç®—å¹³å‡ç½®ä¿¡åº¦"""
        verifications = results.get('verifications', [])
        if not verifications:
            return 0.0
        
        total_confidence = sum(v.get('confidence', 0) for v in verifications)
        return total_confidence / len(verifications)
    
    def _generate_recommendations(self, results: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        hallucination_analysis = results.get('hallucination_analysis', {})
        if hallucination_analysis.get('has_hallucination'):
            recommendations.append("æ£€æµ‹åˆ°æ½œåœ¨å¹»è§‰ï¼Œå»ºè®®å¢åŠ è¯æ®æ£€ç´¢èŒƒå›´")
        
        evidence_coverage = self._calculate_evidence_coverage(results)
        if evidence_coverage < 0.5:
            recommendations.append("è¯æ®è¦†ç›–ç‡è¾ƒä½ï¼Œå»ºè®®æ‰©å……çŸ¥è¯†åº“")
        
        supported_ratio = len([v for v in results.get('verifications', []) if v.get('verdict') == 'SUPPORTED']) / len(results.get('verifications', [1]))
        if supported_ratio < 0.7:
            recommendations.append("æ”¯æŒå£°æ˜æ¯”ä¾‹è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–æ£€ç´¢ç­–ç•¥")
        
        return recommendations if recommendations else ["å›ç­”è´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ"]
    
    def _identify_error_step(self, execution_steps: Dict) -> str:
        """è¯†åˆ«é”™è¯¯å‘ç”Ÿçš„æ­¥éª¤"""
        if not execution_steps:
            return "initialization"
        
        last_step = list(execution_steps.keys())[-1]
        return last_step
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        components_status = {}
        
        for name, component in self.components.items():
            components_status[name] = {
                'initialized': True,
                'type': type(component).__name__
            }
        
        return {
            'status': 'running',
            'components': components_status,
            'timestamp': datetime.now().isoformat(),
            'config_loaded': bool(self.config)
        }
    
    def batch_process(self, queries: List[str], context: Optional[str] = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæŸ¥è¯¢"""
        results = []
        
        for i, query in enumerate(queries, 1):
            self.logger.info(f"ğŸ”„ å¤„ç†æŸ¥è¯¢ {i}/{len(queries)}: {query[:50]}...")
            
            result = self.process_query(query, context)
            results.append(result)
            
            # æ·»åŠ è¿›åº¦ä¿¡æ¯
            result['batch_info'] = {
                'index': i,
                'total': len(queries),
                'progress': f"{i}/{len(queries)}"
            }
        
        return results