#!/usr/bin/env python3
"""
å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ - ä¸»å…¥å£æ–‡ä»¶
é›†æˆæ‰€æœ‰æ¨¡å—ï¼Œæä¾›å‘½ä»¤è¡Œç•Œé¢å’ŒAPIæœåŠ¡å…¥å£
"""

import os
import sys
import argparse
import yaml
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.core.orchestrator import EvidenceEnhancedCorrectionOrchestrator
from src.config.config_loader import load_config, validate_config

class LLMHallucinationCorrectionSystem:
    """å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ - ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        self.config_path = config_path
        self.config = None
        self.orchestrator = None
        self.logger = self._setup_logging()
        self._initialize_system()
    
    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/system.log', encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        return logging.getLogger(__name__)
    
    def _initialize_system(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        try:
            self.logger.info("ğŸš€ åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ")
            
            # åŠ è½½é…ç½®
            self.config = load_config(self.config_path)
            self.logger.info("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            
            # éªŒè¯é…ç½®
            validation_result = validate_config(self.config)
            if not validation_result['valid']:
                self.logger.error(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {validation_result['errors']}")
                raise ValueError("é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥")
            
            # åˆå§‹åŒ–åè°ƒå™¨
            self.orchestrator = EvidenceEnhancedCorrectionOrchestrator(self.config)
            self.logger.info("âœ… ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
            # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
            status = self.orchestrator.get_system_status()
            self.logger.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: {status['status']}")
            
        except Exception as e:
            self.logger.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def process_single_query(self, query: str, context: Optional[str] = None) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæŸ¥è¯¢"""
        self.logger.info(f"ğŸ” å¼€å§‹å¤„ç†æŸ¥è¯¢: {query[:50]}...")
        
        try:
            start_time = datetime.now()
            result = self.orchestrator.process_query(query, context)
            duration = (datetime.now() - start_time).total_seconds()
            
            result['processing_metadata']['total_duration'] = duration
            result['success'] = True
            
            self.logger.info(f"âœ… æŸ¥è¯¢å¤„ç†å®Œæˆ (è€—æ—¶: {duration:.2f}ç§’)")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
            return {
                'success': False,
                'query': query,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def process_batch_queries(self, queries: List[str], context: Optional[str] = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæŸ¥è¯¢"""
        self.logger.info(f"ğŸ“Š å¼€å§‹æ‰¹é‡å¤„ç† {len(queries)} ä¸ªæŸ¥è¯¢")
        
        results = []
        for i, query in enumerate(queries, 1):
            self.logger.info(f"ğŸ”„ å¤„ç†è¿›åº¦: {i}/{len(queries)}")
            
            result = self.process_single_query(query, context)
            result['batch_index'] = i
            result['total_queries'] = len(queries)
            
            results.append(result)
        
        # ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š
        batch_report = self._generate_batch_report(results)
        self.logger.info(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ: {batch_report['summary']}")
        
        return results
    
    def process_file_queries(self, file_path: str, context: Optional[str] = None) -> List[Dict[str, Any]]:
        """ä»æ–‡ä»¶è¯»å–å¹¶å¤„ç†æŸ¥è¯¢"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æŸ¥è¯¢æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        self.logger.info(f"ğŸ“ ä»æ–‡ä»¶è¯»å–æŸ¥è¯¢: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            queries = [line.strip() for line in f if line.strip() and not line.startswith('#')]
        
        self.logger.info(f"ğŸ“‹ è¯»å–åˆ° {len(queries)} ä¸ªæŸ¥è¯¢")
        return self.process_batch_queries(queries, context)
    
    def interactive_mode(self):
        """äº¤äº’å¼æ¨¡å¼"""
        self.logger.info("ğŸ’¬ è¿›å…¥äº¤äº’å¼æ¨¡å¼")
        print("\n" + "="*70)
        print("ğŸ§  å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ - äº¤äº’æ¨¡å¼")
        print("="*70)
        print("è¾“å…¥æ‚¨çš„æŸ¥è¯¢ï¼Œç³»ç»Ÿå°†è¿›è¡Œå¹»è§‰æ£€æµ‹å’Œç­”æ¡ˆçº æ­£")
        print("è¾“å…¥ 'quit', 'exit' æˆ– 'q' é€€å‡º")
        print("-"*70)
        
        while True:
            try:
                query = input("\nâ“ è¯·è¾“å…¥æŸ¥è¯¢: ").strip()
                
                if query.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨!")
                    break
                
                if not query:
                    continue
                
                # å¤„ç†æŸ¥è¯¢
                result = self.process_single_query(query)
                
                # æ˜¾ç¤ºç»“æœ
                self._display_result(result)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨!")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†é”™è¯¯: {e}")
                continue
    
    def _display_result(self, result: Dict[str, Any]):
        """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
        if not result['success']:
            print(f"âŒ å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return
        
        results_data = result['results']
        metadata = result['processing_metadata']
        
        print(f"\nâœ… å¤„ç†æˆåŠŸ! (è€—æ—¶: {metadata['total_duration']:.2f}ç§’)")
        print(f"ğŸ¯ æ„å›¾åˆ†ç±»: {results_data.get('intent', 'æœªçŸ¥')}")
        
        # æ˜¾ç¤ºç­”æ¡ˆå¯¹æ¯”
        initial_answer = results_data.get('initial_answer', '')
        corrected_answer = results_data.get('corrected_answer', '')
        
        print(f"\nğŸ“ åˆå§‹ç­”æ¡ˆ (é•¿åº¦: {len(initial_answer)} å­—ç¬¦):")
        print("-" * 50)
        print(initial_answer[:300] + "..." if len(initial_answer) > 300 else initial_answer)
        print("-" * 50)
        
        print(f"\nâœï¸ çº æ­£åç­”æ¡ˆ (é•¿åº¦: {len(corrected_answer)} å­—ç¬¦):")
        print("-" * 50)
        print(corrected_answer[:300] + "..." if len(corrected_answer) > 300 else corrected_answer)
        print("-" * 50)
        
        # æ˜¾ç¤ºéªŒè¯ç»Ÿè®¡
        verifications = results_data.get('verifications', [])
        if verifications:
            supported = len([v for v in verifications if v.get('verdict') == 'SUPPORTED'])
            contradicted = len([v for v in verifications if v.get('verdict') == 'CONTRADICTED'])
            total = len(verifications)
            
            print(f"\nğŸ“Š å£°æ˜éªŒè¯ç»Ÿè®¡:")
            print(f"  â€¢ æ€»å£°æ˜æ•°: {total}")
            print(f"  â€¢ æ”¯æŒå£°æ˜: {supported} ({supported/total*100:.1f}%)")
            print(f"  â€¢ çŸ›ç›¾å£°æ˜: {contradicted} ({contradicted/total*100:.1f}%)")
        
        # æ˜¾ç¤ºå¹»è§‰æ£€æµ‹ç»“æœ
        hallucination_analysis = results_data.get('hallucination_analysis', {})
        if hallucination_analysis.get('has_hallucination'):
            print(f"\nâš ï¸  å¹»è§‰æ£€æµ‹: æ£€æµ‹åˆ°æ½œåœ¨å¹»è§‰")
            affected_sections = hallucination_analysis.get('affected_sections', [])
            for section in affected_sections[:3]:  # æ˜¾ç¤ºå‰3ä¸ªå—å½±å“éƒ¨åˆ†
                print(f"  â€¢ {section.get('text', '')[:50]}...")
        else:
            print(f"\nâœ… å¹»è§‰æ£€æµ‹: æœªæ£€æµ‹åˆ°æ˜æ˜¾å¹»è§‰")
        
        # æ˜¾ç¤ºæ”¹è¿›å»ºè®®
        final_report = results_data.get('final_report', {})
        recommendations = final_report.get('recommendations', [])
        if recommendations:
            print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
            for rec in recommendations:
                print(f"  â€¢ {rec}")
    
    def _generate_batch_report(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š"""
        successful = [r for r in results if r.get('success')]
        failed = [r for r in results if not r.get('success')]
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        quality_metrics = []
        for result in successful:
            if 'results' in result:
                verifications = result['results'].get('verifications', [])
                if verifications:
                    supported = len([v for v in verifications if v.get('verdict') == 'SUPPORTED'])
                    quality_metrics.append(supported / len(verifications))
        
        avg_quality = sum(quality_metrics) / len(quality_metrics) if quality_metrics else 0
        
        return {
            'summary': {
                'total_queries': len(results),
                'successful': len(successful),
                'failed': len(failed),
                'success_rate': len(successful) / len(results) * 100,
                'average_quality': avg_quality
            },
            'timestamp': datetime.now().isoformat()
        }
    
    def export_results(self, results: List[Dict[str, Any]], output_format: str = 'json') -> str:
        """å¯¼å‡ºå¤„ç†ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path('results')
        output_dir.mkdir(exist_ok=True)
        
        if output_format == 'json':
            output_file = output_dir / f"results_{timestamp}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            return str(output_file)
        
        elif output_format == 'csv':
            # ç®€åŒ–çš„CSVå¯¼å‡º
            output_file = output_dir / f"results_{timestamp}.csv"
            # è¿™é‡Œå¯ä»¥æ·»åŠ CSVå¯¼å‡ºé€»è¾‘
            return str(output_file)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {output_format}")
    
    def get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        if not self.orchestrator:
            return {'status': 'æœªåˆå§‹åŒ–'}
        
        status = self.orchestrator.get_system_status()
        return {
            'system': {
                'name': 'å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ',
                'version': '1.0.0',
                'status': status['status'],
                'initialized': True,
                'timestamp': datetime.now().isoformat()
            },
            'components': status.get('components', {}),
            'config': {
                'llm_provider': self.config['llm']['provider'],
                'vector_db': self.config['vector_db']['collection_name'],
                'retrieval_threshold': self.config['retrieval']['similarity_threshold']
            }
        }

def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œå…¥å£ç‚¹"""
    parser = argparse.ArgumentParser(
        description='å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹ä¸çº æ­£ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # äº¤äº’æ¨¡å¼
  python main.py --interactive
  
  # å¤„ç†å•ä¸ªæŸ¥è¯¢
  python main.py --query "æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ"
  
  # ä»æ–‡ä»¶å¤„ç†æŸ¥è¯¢
  python main.py --file queries.txt
  
  # æ‰¹é‡å¤„ç†å¹¶å¯¼å‡ºç»“æœ
  python main.py --batch queries.txt --export json
  
  # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
  python main.py --status
        """
    )
    
    parser.add_argument('--config', '-c', default='config/config.yaml', 
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/config.yaml)')
    parser.add_argument('--query', '-q', help='ç›´æ¥å¤„ç†å•ä¸ªæŸ¥è¯¢')
    parser.add_argument('--file', '-f', help='ä»æ–‡ä»¶è¯»å–æŸ¥è¯¢')
    parser.add_argument('--batch', '-b', help='æ‰¹é‡å¤„ç†æ–‡ä»¶ä¸­çš„æŸ¥è¯¢')
    parser.add_argument('--interactive', '-i', action='store_true', 
                       help='è¿›å…¥äº¤äº’æ¨¡å¼')
    parser.add_argument('--status', '-s', action='store_true', 
                       help='æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€')
    parser.add_argument('--export', choices=['json', 'csv'], 
                       help='å¯¼å‡ºç»“æœæ ¼å¼ (json/csv)')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true', 
                       help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        system = LLMHallucinationCorrectionSystem(args.config)
        
        # å¤„ç†ä¸åŒæ¨¡å¼
        if args.status:
            # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
            info = system.get_system_info()
            print(json.dumps(info, indent=2, ensure_ascii=False))
            return
        
        if args.query:
            # å•æ¬¡æŸ¥è¯¢æ¨¡å¼
            result = system.process_single_query(args.query)
            system._display_result(result)
            
            if args.export:
                output_file = system.export_results([result], args.export)
                print(f"ğŸ’¾ ç»“æœå·²å¯¼å‡ºåˆ°: {output_file}")
        
        elif args.file or args.batch:
            # æ–‡ä»¶æ‰¹é‡å¤„ç†æ¨¡å¼
            file_path = args.file or args.batch
            results = system.process_file_queries(file_path)
            
            if args.export:
                output_file = system.export_results(results, args.export)
                print(f"ğŸ’¾ æ‰¹é‡ç»“æœå·²å¯¼å‡ºåˆ°: {output_file}")
            else:
                # æ˜¾ç¤ºæ‰¹é‡å¤„ç†æ‘˜è¦
                report = system._generate_batch_report(results)
                print(f"\nğŸ“Š æ‰¹é‡å¤„ç†æŠ¥å‘Š:")
                print(f"  æ€»æŸ¥è¯¢æ•°: {report['summary']['total_queries']}")
                print(f"  æˆåŠŸå¤„ç†: {report['summary']['successful']}")
                print(f"  å¤„ç†å¤±è´¥: {report['summary']['failed']}")
                print(f"  æˆåŠŸç‡: {report['summary']['success_rate']:.1f}%")
                print(f"  å¹³å‡è´¨é‡: {report['summary']['average_quality']:.3f}")
        
        elif args.interactive:
            # äº¤äº’æ¨¡å¼
            system.interactive_mode()
        
        else:
            # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©
            parser.print_help()
    
    except Exception as e:
        logging.error(f"âŒ ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
        print(f"é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()